---
  title: "FIR_univariate_byrun_&_13_19"
author: "WBR"
date: "7/13/2019"
output: html_document
---
  
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
# knitr::opts_chunk$set(out.width = "70%")
```

## Bold data but renamed similarity so plotting is compatible!!
# FS rois and HIPP
```{r}

# RSA sum stats
library(tidyverse)
library(afex)
library(ggforce)
library('emmeans')

# SVSS with positions and beta threshold
rsa = rsa = read.table("/Users/wbr/walter/fmri/sms_scan_analyses/rsa_singletrial/rsa_fir/univariate_FSants_6_28_19.txt", header = TRUE, stringsAsFactors = TRUE)

rsa$runnum = gsub(".nii", "", rsa$runnum)

# noisiest subject
bad_subs = c('s001', "s008","s016", "s027","s043","s032","s039") # , "s041"
rsa$drop_subs = rsa$sub %in% bad_subs
rsa = rsa[!(rsa$drop_subs == TRUE),]

# s022 rh-prc is messed up, 20 most negatvie correlations in whole dataset. NA all of those for time being
# rsa$too_low = rsa$similarity < -.4
# rsa = rsa[!(rsa$too_low == TRUE),]
# ## a couple that are 1 somehow..
# rsa$too_high = rsa$similarity > .8
# rsa = rsa[!(rsa$too_high == TRUE),]

# drop na's
rsa = rsa %>% drop_na(bold)

# condense over different sequences in a condition and different runs
rsa = rsa %>% group_by(sub,condition,roi,position, runnum) %>% summarise(similarity = mean(bold)) %>%  ungroup()

rsa.sumstats = rsa %>% group_by(roi, condition) %>% summarise(mean = mean(similarity), sd = sd(similarity)) %>% ungroup()


# the rois
PM_rois = c('near-phc-ant-L', 'near-phc-ant-R', 'lh-ANG', 'rh-ANG', 'lh-PCC', 'rh-PCC',	'lh-Prec',	'rh-Prec', 'lh-RSC', 'rh-RSC')
AT_rois = c('near-prc-L',	'near-prc-R', 	'lh-TPole', 	'rh-TPole', 'lh-OFC', 'rh-OFC')
HIPP_rois = c('near_hipp_body_L',	'near_hipp_body_R',	'near_hipp_head_L',	'near_hipp_head_R', 'near_hipp_tail_L', 'near_hipp_tail_R')
PM_HIPP_rois = c('near-hipp-body-L',	'near-hipp-body-R',	'near-hipp-head-L',	'near-hipp-head-R', 
                 'near-phc-ant-L', 'near-phc-ant-R', 'lh-ANG', 'rh-ANG', 'lh-PCC', 'rh-PCC',	'lh-Prec',	'rh-Prec', 'lh-RSC', 'rh-RSC')
IFG= c( 'lh-inf-opercular', 'lh-inf-triang', 'rh-inf-opercular', 'rh-inf-triang', 'rh-inf-orbital', 'lh-inf-orbital')
frontal = c( 'lh-inf-opercular', 'lh-inf-triang', 'rh-inf-opercular', 'rh-inf-triang', 'rh-inf-orbital', 'lh-inf-orbital','rh-insula-inf','lh-insula-inf','rh-insula-short','lh-insula-short','lh-VMPFC','rh-VMPFC','lh-MPFC','rh-MPFC','rh-MTG','lh-MTG','rh-OFC','lh-OFC')
# 'lh-insula-short', 'lh-insula-inf','rh-insula-short', 'rh-insula-inf', 
# vmpfc = c('near-VMPFC') 

# make networks factor
# first make logical vectors for member regions
rsa$PM = rsa$roi %in% PM_rois
rsa$AT = rsa$roi %in% AT_rois
rsa$HIPP = rsa$roi %in% HIPP_rois
rsa$PM_HIPP = rsa$roi %in% PM_HIPP_rois
rsa$IFG = rsa$roi %in% IFG
rsa$frontal = rsa$roi %in% frontal

# now assign group label in single column
# rsa$roi_group = ifelse(rsa$PM == TRUE, "PM", ifelse(rsa$AT == TRUE, "AT", ifelse(rsa$HIPP == TRUE,"HIPP", "Other" )))
rsa$roi_group = ifelse(rsa$PM == TRUE, "PM", ifelse(rsa$AT == TRUE, "AT", ifelse(rsa$HIPP == TRUE,"HIPP", ifelse(rsa$frontal == TRUE, "frontal", ifelse(rsa$IFG == TRUE, "IFG","Other")))))
# delete the logical vectors
rsa[,7:12] = NULL
# make group a factor
rsa$roi_group = as.factor(rsa$roi_group)

# wish I did this earlier but hindsight yada yada
rsa$roi = gsub(".*body-L$", "lh-hipp-body", rsa$roi)
rsa$roi = gsub(".*body-R$", "rh-hipp-body", rsa$roi)
rsa$roi = gsub(".*head-L$", "lh-hipp-head", rsa$roi)
rsa$roi = gsub(".*head-R$", "rh-hipp-head", rsa$roi)
rsa$roi = gsub(".*tail-L$", "lh-hipp-tail", rsa$roi)
rsa$roi = gsub(".*tail-R$", "rh-hipp-tail", rsa$roi)
rsa$roi = gsub(".*ant-L$", "lh-phc-ant", rsa$roi)
rsa$roi = gsub(".*ant-R$", "rh-phc-ant", rsa$roi)
# rsa$roi = gsub(".*VMPFC", "VMPFC", rsa$roi)
rsa$roi = gsub(".*prc-L$", "lh-prc", rsa$roi)
rsa$roi = gsub(".*prc-R$", "rh-prc", rsa$roi)
########################
# PMAT AT and HIPP only
rsa.PMAT = rsa %>% filter(roi_group != "Other") %>% filter(roi_group != "IFG")  %>% filter(roi_group != "frontal")
rsa.frontal = rsa %>% filter(rsa$roi_group == "frontal")

# rt  diffs
rt.diffs =  read.csv("rtdiffs_11_1_18.csv")
rt.diffs[,1] =NULL 

# nice labels
PM_labs = c('lh-phc-ant', 'rh-phc-ant', 'lh-ANG', 'rh-ANG', 'lh-PCC', 'rh-PCC',	'lh-Prec',	'rh-Prec', 'lh-RSC', 'rh-RSC')
AT_labs = c('lh-prc',	'rh-prc', 	'lh-TPole', 	'rh-TPole', 'lh-OFC', 'rh-OFC')
HIPP_labs = c('lh-hipp-body','rh-hipp-body','lh-hipp-head','rh-hipp-head','lh-hipp-tail','rh-hipp-tail')

```

# Glasser rois
```{r}
# RSA sum stats
library(tidyverse)
library(afex)
library(ggforce)
library('emmeans')
library(parallel) 

# SVSS with positions and beta threshold
rsa = read.table("/Users/wbr/walter/fmri/sms_scan_analyses/rsa_singletrial/rsa_fir/univariate_fir_glass_2_23_19.txt", header = TRUE, stringsAsFactors = TRUE)

rsa$runnum = gsub(".nii", "", rsa$runnum)

# write_csv(rsa,"2_25_19_univariate_glasser_df.csv")

# noisiest subject
bad_subs = c('s001', "s008","s016", "s027","s043", "s032","s039") # , "s041"    
rsa$drop_subs = rsa$sub %in% bad_subs
rsa = rsa[!(rsa$drop_subs == TRUE),]


# extreme vals
# rsa$too_low = rsa$similarity < -.5
# rsa = rsa[!(rsa$too_low == TRUE),]
# ## a couple that are 1 somehow..
# rsa$too_high = rsa$similarity > .8
# rsa = rsa[!(rsa$too_high == TRUE),]
# drop na's
rsa = rsa %>% drop_na(bold)
       
# condense over different sequences in a condition and different runs
rsa = rsa %>% group_by(sub,condition,roi,position,runnum) %>% summarise(similarity = mean(bold)) %>%  ungroup()

# fix roi labels
rsa$roi = gsub("-", "_", rsa$roi)
rsa$roi = gsub("reslice_", "", rsa$roi)

# # PMAT 3.0 labels
# # modulelabs = read.table("2_18_glasser_pmat_labels_forR.csv",header = TRUE, stringsAsFactors = TRUE, sep =",")
# # adds node strength
# modulelabs = read.table("2_20_glasser_pmat_nodestrength.csv",header = TRUE, stringsAsFactors = TRUE, sep =",")
# # convert nodestrength to percentile
# modulelabspct = modulelabs %>%  group_by(Module) %>% mutate(p_node = percent_rank(node_strength)) %>% ungroup()
# topmodulelabs = modulelabspct %>% filter(p_node >= .15)
# 
# LANGrois = topmodulelabs %>%  filter(Module == 1)
# PMrois = topmodulelabs %>%  filter(Module == 2)
# ATrois = topmodulelabs %>%  filter(Module == 3)
# 
# # LANGrois = modulelabs %>%  filter(Module == 1)
# # PMrois = modulelabs %>%  filter(Module == 2)
# # ATrois = modulelabs %>%  filter(Module == 3)
# 
# # problem ROI, needs investigating
# PMrois = PMrois %>%  filter(ROI != "L_s6-8_ROI")
# 
# # make networks factor
# rsa$lang = rsa$roi %in% LANGrois$ROI
# rsa$AT = rsa$roi %in% ATrois$ROI
# rsa$PM = rsa$roi %in% PMrois$ROI
# 
# rsa$vischeck = grepl(".*V1_ROI",rsa$roi)
# # rsa$vischeck = grepl(".*V\\d.*",rsa$roi)
# 
# # now assign group label in single column
# rsa$roi_group = ifelse(rsa$PM == TRUE, "PM", ifelse(rsa$AT == TRUE, "AT", ifelse(rsa$lang == TRUE, "LANG", ifelse(rsa$vischeck == TRUE, "VIS", "other"))))

# 10_9_19 4net module labs
modulelabs = read.table("4net_labels_10_9_19.csv",header = TRUE, stringsAsFactors = TRUE, sep =",")
modulelabs$ROI = gsub("-", "_", modulelabs$ROI)
PMrois = modulelabs %>%  filter(network == 1)
LATrois = modulelabs %>%  filter(network == 2)
ATrois = modulelabs %>%  filter(network == 3)
FPNrois = modulelabs %>%  filter(network == 4)

# problem ROI, needs investigating
# PMrois = PMrois %>%  filter(ROI != "L_s6-8_ROI")
PMrois = PMrois %>%  filter(ROI != "L_s6_8_ROI")


# make networks factor
rsa$LAT = rsa$roi %in% LATrois$ROI
rsa$AT = rsa$roi %in% ATrois$ROI
rsa$PM = rsa$roi %in% PMrois$ROI
rsa$FPN = rsa$roi %in% FPNrois$ROI

# rsa$vischeck = grepl(".*V\\d.*",rsa$roi)

# now assign group label in single column
rsa$roi_group = ifelse(rsa$PM == TRUE, "PM", ifelse(rsa$AT == TRUE, "AT", ifelse(rsa$LAT == TRUE, "LAT", ifelse(rsa$FPN == TRUE, "FPN", "other"))))

# delete the logical vectors
rsa[,7:10] = NULL
# make group a factor
rsa$roi_group = as.factor(rsa$roi_group)

###### adding sub networks 
# # mpfc_subgroup = modulelabs %>% filter(sub_group == "mpfc")
# # pm_subgroup = modulelabs %>% filter(sub_group == "posterior_medial")
# # lp_subgroup = modulelabs %>% filter(sub_group == "lateral_parietal")
# # t_subgroup = modulelabs %>% filter(sub_group == "temporal")
# # d_subgroup = modulelabs %>% filter(sub_group == "dpfc")
# # mtl_subgroup = modulelabs %>% filter(sub_group == "mtl")
# # 
# # rsa$pm_subgroup = rsa$roi %in% pm_subgroup$ROI
# # rsa$mpfc_subgroup = rsa$roi %in% mpfc_subgroup$ROI
# # rsa$lp_subgroup = rsa$roi %in% lp_subgroup$ROI
# # rsa$t_subgroup = rsa$roi %in% t_subgroup$ROI
# # rsa$d_subgroup = rsa$roi %in% d_subgroup$ROI
# # rsa$mtl_subgroup = rsa$roi %in% mtl_subgroup$ROI
# # 
# # rsa$sub_group = ifelse(rsa$mpfc_subgroup == TRUE, "mpfc", ifelse(rsa$pm_subgroup == TRUE,"pm_sub",ifelse(rsa$lp_subgroup == TRUE, "lp",ifelse(rsa$t_subgroup == TRUE, "temporal",ifelse(rsa$d_subgroup == TRUE, "dorsal",ifelse(rsa$mtl_subgroup == TRUE, "mtl","tbd"))))))
# # rsa$sub_group = as.factor(rsa$sub_group)
# # 
# # 
# # 
# # rsa$othergroup = ifelse(rsa$sub_group == "lp" | rsa$sub_group == "pm_sub", "PM_super","other")
# 
# rsa[,8:13] = NULL

#############
# rsa = read_csv("2_25_19_univariate_glasser_df.csv")

#################
# rt  diffs
rt.diffs =  read.csv("rtdiffs_11_1_18.csv")
rt.diffs[,1] =NULL 

```

```{r}
# adding runnum grouping
wbr.sliding.ttest.network = function(midval,region,winval,con1,con2,run) {
  # grab grouped/meaned data for each condition 
  temp.df = rsa %>% filter(roi_group == region) %>% filter(condition == con1, runnum == run) %>%   filter(position %in% (midval-winval):(midval+winval)) %>% group_by(sub) %>% summarise(similarity = mean(similarity)) %>%  ungroup()
  temp.df = droplevels(temp.df)
  dat1 = temp.df$similarity
  
  temp.df = rsa %>% filter(roi_group == region) %>% filter(condition == con2, runnum == run) %>%   filter(position %in% (midval-winval):(midval+winval)) %>% group_by(sub) %>% summarise(similarity = mean(similarity)) %>%  ungroup()
  temp.df = droplevels(temp.df)
  dat2 = temp.df$similarity
  
  # run ttest
  if (length(dat1) == length(dat2)  && length(dat1) > 0){
    print(region)
    result = t.test(dat1, dat2, paired = TRUE)
    pval = result$p.value
    tval = result$statistic
    out = c(pval,tval)
    return(out)
  } else {
    sprintf('problem with %s !!!',region )
  }
}
```

#nothing suuper eye catching in hippocampus by run analyses, except maybe overall slight tendency for more intact activity at the end of seqeunce in run1 

# huge effect for intact in PM at end of first run (hint of effect at the very beginning)
# second run looks quite different, early scrambled, then sustained intact in middle
# run 3 not a lot going on. scrambled early then NS sustained scrambled 

AT is actually pretty similar to PM

Lang also has late intact effect in run1
Early and late scrmabled in run2
nada in run3


PM effect in run 1
pm_sub up to 4.35 for late effect, flipping earlier, need to look not at difference
lp has early effect and late effect
mtl is peaked...
temporal nothing really

mpfc is -3.6 at tp 6 run2 -- 


tbd      mpfc     pm_sub   dorsal   lp       mtl      temporal
```{r}
# use this to get the true tstats for every timepoint. Chunk below will be used to ID cluster mass threshold
tstatdat = lapply(1:32,wbr.sliding.ttest.network,winval=0,region="PM",con1="intact",con2="scrambled", run="run1")
tstatdat = data.frame(matrix(unlist(tstatdat), nrow=32, byrow=T))
tstatdat$timepoint = 1:32
tstatdat = plyr::rename(tstatdat, c("X1"="pval","X2"="tval"))

#plot that shit
tstat.plot = ggplot(data = tstatdat,(aes(x =timepoint , y= tval,group =1)))  + geom_point(size = 3) +geom_line(size =2) + theme(text = element_text(size = 30, face = "bold"))  + ylab("t stat")  +
  geom_hline(aes(yintercept = 0)) + scale_y_continuous(limits= c(-4.5 , 4.5),breaks = c(-4,-3,-2,-1,0,1,2,3,4)) #+ ggtitle("AT univariate run3")
# geom_segment(x = 18,y =-.25,xend= 18,yend = .25, color = "red",size=.75) 

tstat.plot
# ggsave("july19/tstat_at_uni_run3.pdf", plot = tstat.plot, dpi = 600,width = 8, height = 5,units = "in")
```

# line for each condition instead of difference/tstat line plot
```{r}
rsa.PM = rsa %>% filter(rsa$roi_group == "HIPP") 
rsa.PM = rsa.PM %>%  filter(roi %in% c("near_hipp_head_R","near_hipp_body_R"), condition != "random")
line.dat = rsa.PM  %>% group_by(condition,position,runnum) %>% summarise(similarity = mean(similarity))


PM.line = ggplot(data = line.dat, aes(x = position,group = condition, y = similarity)) + geom_line(aes(linetype=condition)) + facet_wrap(~runnum) + ylab("BOLD") + xlab("TR") + ggtitle("All Hipp Univariate")
  # + theme(text = element_text(size = 30, face = "bold"),axis.title.x=element_blank(),axis.text.x=element_text(angle = -45,hjust = 0)) + scale_x_discrete(labels = c("Intact", "Same Verb","Same Position","Scrambled"))
  
PM.line
# ggsave("july19/allhipp_uni_meantimecourses_byrun.pdf", plot = PM.line, dpi = 600,width = 10, height = 5,units = "in")
```


#########################
correct for timepoint MC with permutation tests

# start with func for computing true sliding window condition mean difference time courses
```{r}
make.sliding.df = function(midval,network,winval,con1,con2,run) {
# grab grouped/meaned data for each condition 
temp.df = rsa %>% filter(roi_group == network,condition == con1,runnum == run) %>%   filter(position %in% (midval-winval):(midval+winval)) %>% group_by(sub) %>% summarise(similarity = mean(similarity)) %>%  ungroup()
temp.df = droplevels(temp.df)
dat1 = temp.df$similarity

temp.df = rsa %>% filter(roi_group == network) %>% filter(condition == con2) %>%   filter(position %in% (midval-winval):(midval+winval)) %>% group_by(sub) %>% summarise(similarity = mean(similarity)) %>%  ungroup()
dat2 = temp.df$similarity

temp.df$diff = dat1-dat2
temp.df$similarity =NULL
temp.df$timepoint = rep(midval,27)
return(temp.df)
# compute difference between means
# temp.df = temp.df %>% mutate(cond.diff = )
}
```

```{r}
# execute the above function for every timepoint, returning a list of df's, one for each timepoint, that contain mean differences for every subject
library(parallel)
# Calculate the number of cores
no_cores = detectCores() - 1
# Initiate cluster
cl = makeCluster(no_cores,type = "FORK")

list_of_dfs = NULL
list_of_dfs = parLapply(cl,1:32,make.sliding.df,winval=0,run="run1",network="LANG",con1="intact",con2="scrambled")
timecourse_dat= do.call(rbind,list_of_dfs)

stopCluster(cl)
```

```{r}
ttestfunky = function(cur_tp,data){
  temp_timecourse_dat =data
  temp.df = temp_timecourse_dat %>% filter(timepoint == cur_tp)
temp.df = droplevels(temp.df)
dat1 = temp.df$permdiff

if (length(dat1) == 27){
  result = t.test(dat1)
  # pval = result$p.value
  tval = result$statistic
  out = c(tval)
  return(out)
} else {
  warning("\nSomething funked up!\n")
}
}
```

```{r}

# generate random condition flip for each subject and apply identically for every timepoint within a sub
perm.data = function(permnum){
  print(sprintf('Perm #%d',permnum))
  labshuffle = rep(sample(c(-1,1),27,replace=TRUE),32)
  temp_timecourse_dat = timecourse_dat
  temp_timecourse_dat = temp_timecourse_dat %>% mutate(permdiff = diff*labshuffle)
  return(temp_timecourse_dat)
}

# calls ttest funky to run ttests for each timepoint
evaltval = function(data){
  temp_timecourse_dat = data
  tvals = unlist(lapply(1:25,ttestfunky,temp_timecourse_dat))
  maxt = max(tvals)
  # mint = min(tvals)
  # if (abs(maxt) > abs(mint)){
  #   outval = maxt
  # } else {
  #   outval = mint
  # }
  # outval = mint
  outval = maxt
  return(outval)
  
  # cluster size instead of max tval
  # pvals = unlist(lapply(1:25,ttestfunky,temp_timecourse_dat))
  # smallps = pvals < .05
  # # magic to find max consecutive TRUEs
  # clustsize = max(rle(smallps)$lengths[rle(smallps)$values])
  # if (clustsize < 1){
  #   clustsize = 0
  # }
  # return(clustsize)
}

run.the.perms = function(permnum){
  temp_timecourse_dat = perm.data(permnum)
  outval = evaltval(temp_timecourse_dat)
  return(outval)
}

```

### finally run the perms
```{r}
# Calculate the number of cores
no_cores = detectCores() - 1
# Initiate cluster
cl = makeCluster(no_cores,type = "FORK")

permhist = unlist(parLapply(cl,1:10000,run.the.perms))

stopCluster(cl)

perm.df = data.frame(permhist)
perm.df = perm.df %>% mutate(ptile = percent_rank(permhist))
```




