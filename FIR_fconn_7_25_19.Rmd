---
  title: "FIR_univariate_byrun_&_13_19"
author: "WBR"
date: "7/13/2019"
output: html_document
---
  
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
# knitr::opts_chunk$set(out.width = "70%")
```

## Bold data but renamed similarity so plotting is compatible!!
# FS rois and HIPP
```{r}

# RSA sum stats
library(tidyverse)
library(afex)
library(ggforce)
library('emmeans')
library(purrr)

# SVSS with positions and beta threshold
rsa = read.table("/Users/wbr/walter/fmri/sms_scan_analyses/rsa_singletrial/rsa_fir/univariate_FSants_6_28_19.txt", header = TRUE, stringsAsFactors = TRUE)

rsa$runnum = gsub(".nii", "", rsa$runnum)

# noisiest subject
bad_subs = c('s001', "s008","s016", "s027","s043","s032","s039") # , "s041"
rsa$drop_subs = rsa$sub %in% bad_subs
rsa = rsa[!(rsa$drop_subs == TRUE),]
rsa$sub = droplevels(rsa$sub)

# s022 rh-prc is messed up, 20 most negatvie correlations in whole dataset. NA all of those for time being
# rsa$too_low = rsa$similarity < -.4
# rsa = rsa[!(rsa$too_low == TRUE),]
# ## a couple that are 1 somehow..
# rsa$too_high = rsa$similarity > .8
# rsa = rsa[!(rsa$too_high == TRUE),]

# drop na's
rsa = rsa %>% drop_na(bold)

# condense over different sequences in a condition and different runs
# rsa = rsa %>% group_by(sub,condition,roi,position, runnum) %>% summarise(similarity = mean(bold)) %>%  ungroup()
rsa$similarity = rsa$bold
rsa$bold = NULL
rsa$drop_subs = NULL


# the rois
PM_rois = c('near-phc-ant-L', 'near-phc-ant-R', 'lh-ANG', 'rh-ANG', 'lh-PCC', 'rh-PCC',	'lh-Prec',	'rh-Prec', 'lh-RSC', 'rh-RSC')
AT_rois = c('near-prc-L',	'near-prc-R', 	'lh-TPole', 	'rh-TPole', 'lh-OFC', 'rh-OFC')
HIPP_rois = c('near_hipp_body_L',	'near_hipp_body_R',	'near_hipp_head_L',	'near_hipp_head_R')# no tail plz, 'near_hipp_tail_L', 'near_hipp_tail_R')
PM_HIPP_rois = c('near-hipp-body-L',	'near-hipp-body-R',	'near-hipp-head-L',	'near-hipp-head-R', 
                 'near-phc-ant-L', 'near-phc-ant-R', 'lh-ANG', 'rh-ANG', 'lh-PCC', 'rh-PCC',	'lh-Prec',	'rh-Prec', 'lh-RSC', 'rh-RSC')
IFG= c( 'lh-inf-opercular', 'lh-inf-triang', 'rh-inf-opercular', 'rh-inf-triang', 'rh-inf-orbital', 'lh-inf-orbital')
frontal = c( 'lh-inf-opercular', 'lh-inf-triang', 'rh-inf-opercular', 'rh-inf-triang', 'rh-inf-orbital', 'lh-inf-orbital','rh-insula-inf','lh-insula-inf','rh-insula-short','lh-insula-short','lh-VMPFC','rh-VMPFC','lh-MPFC','rh-MPFC','rh-MTG','lh-MTG','rh-OFC','lh-OFC')
# 'lh-insula-short', 'lh-insula-inf','rh-insula-short', 'rh-insula-inf', 
# vmpfc = c('near-VMPFC') 

# make networks factor
# first make logical vectors for member regions
rsa$PM = rsa$roi %in% PM_rois
rsa$AT = rsa$roi %in% AT_rois
rsa$HIPP = rsa$roi %in% HIPP_rois
rsa$PM_HIPP = rsa$roi %in% PM_HIPP_rois
rsa$IFG = rsa$roi %in% IFG
rsa$frontal = rsa$roi %in% frontal

# now assign group label in single column
# rsa$roi_group = ifelse(rsa$PM == TRUE, "PM", ifelse(rsa$AT == TRUE, "AT", ifelse(rsa$HIPP == TRUE,"HIPP", "Other" )))
rsa$roi_group = ifelse(rsa$PM == TRUE, "PM", ifelse(rsa$AT == TRUE, "AT", ifelse(rsa$HIPP == TRUE,"HIPP", ifelse(rsa$frontal == TRUE, "frontal", ifelse(rsa$IFG == TRUE, "IFG","Other")))))
# delete the logical vectors
rsa[,8:13] = NULL
# make group a factor
rsa$roi_group = as.factor(rsa$roi_group)

# wish I did this earlier but hindsight yada yada
rsa$roi = gsub(".*body-L$", "lh-hipp-body", rsa$roi)
rsa$roi = gsub(".*body-R$", "rh-hipp-body", rsa$roi)
rsa$roi = gsub(".*head-L$", "lh-hipp-head", rsa$roi)
rsa$roi = gsub(".*head-R$", "rh-hipp-head", rsa$roi)
rsa$roi = gsub(".*tail-L$", "lh-hipp-tail", rsa$roi)
rsa$roi = gsub(".*tail-R$", "rh-hipp-tail", rsa$roi)
rsa$roi = gsub(".*ant-L$", "lh-phc-ant", rsa$roi)
rsa$roi = gsub(".*ant-R$", "rh-phc-ant", rsa$roi)
# rsa$roi = gsub(".*VMPFC", "VMPFC", rsa$roi)
rsa$roi = gsub(".*prc-L$", "lh-prc", rsa$roi)
rsa$roi = gsub(".*prc-R$", "rh-prc", rsa$roi)
########################
# PMAT AT and HIPP only
rsa.PMAT = rsa %>% filter(roi_group != "Other") %>% filter(roi_group != "IFG")  %>% filter(roi_group != "frontal")
rsa.frontal = rsa %>% filter(rsa$roi_group == "frontal")

# rt  diffs
rt.diffs =  read.csv("rtdiffs_11_1_18.csv")
rt.diffs[,1] =NULL 

# nice labels
PM_labs = c('lh-phc-ant', 'rh-phc-ant', 'lh-ANG', 'rh-ANG', 'lh-PCC', 'rh-PCC',	'lh-Prec',	'rh-Prec', 'lh-RSC', 'rh-RSC')
AT_labs = c('lh-prc',	'rh-prc', 	'lh-TPole', 	'rh-TPole', 'lh-OFC', 'rh-OFC')
HIPP_labs = c('lh-hipp-body','rh-hipp-body','lh-hipp-head','rh-hipp-head','lh-hipp-tail','rh-hipp-tail')

# in this script actually just want hipp rois..
rsa = rsa[(rsa$roi_group == "HIPP"),]

rsa$sub_group = rsa$roi_group
rsa$roi_group  = NULL

rsa = rsa %>% group_by(sub,condition,sub_group,position,runnum,seqnum) %>% summarise(similarity = mean(similarity)) %>%  ungroup()

hipp_rsa = rsa

# write_csv(hipp_rsa,"fconn_hipp_dat.csv")
```

# Glasser rois
```{r}
# RSA sum stats
library(tidyverse)
library(afex)
library(ggforce)
library('emmeans')
library(parallel) 

# SVSS with positions and beta threshold
rsa = read.table("/Users/wbr/walter/fmri/sms_scan_analyses/rsa_singletrial/rsa_fir/univariate_fir_glass_2_23_19.txt", header = TRUE, stringsAsFactors = TRUE)

rsa$runnum = gsub(".nii", "", rsa$runnum)

# write_csv(rsa,"2_25_19_univariate_glasser_df.csv")

# noisiest subject
bad_subs = c('s001', "s008","s016", "s027","s043", "s032","s039") # , "s041"    
rsa$drop_subs = rsa$sub %in% bad_subs
rsa = rsa[!(rsa$drop_subs == TRUE),]


# extreme vals
# rsa$too_low = rsa$similarity < -.5
# rsa = rsa[!(rsa$too_low == TRUE),]
# ## a couple that are 1 somehow..
# rsa$too_high = rsa$similarity > .8
# rsa = rsa[!(rsa$too_high == TRUE),]
# drop na's
rsa = rsa %>% drop_na(bold)
       
# condense over different sequences in a condition and different runs
# rsa = rsa %>% group_by(sub,condition,roi,position,runnum) %>% summarise(similarity = mean(bold)) %>%  ungroup()

# fix roi labels
rsa$roi = gsub("-", "_", rsa$roi)
rsa$roi = gsub("reslice_", "", rsa$roi)

# PMAT 3.0 labels
# modulelabs = read.table("2_18_glasser_pmat_labels_forR.csv",header = TRUE, stringsAsFactors = TRUE, sep =",")
# adds node strength
modulelabs = read.table("2_20_glasser_pmat_nodestrength.csv",header = TRUE, stringsAsFactors = TRUE, sep =",")
# convert nodestrength to percentile
modulelabspct = modulelabs %>%  group_by(Module) %>% mutate(p_node = percent_rank(node_strength)) %>% ungroup()
topmodulelabs = modulelabspct %>% filter(p_node >= .15)

LANGrois = topmodulelabs %>%  filter(Module == 1)
PMrois = topmodulelabs %>%  filter(Module == 2)
ATrois = topmodulelabs %>%  filter(Module == 3)

# LANGrois = modulelabs %>%  filter(Module == 1)
# PMrois = modulelabs %>%  filter(Module == 2)
# ATrois = modulelabs %>%  filter(Module == 3)

# problem ROI, needs investigating
PMrois = PMrois %>%  filter(ROI != "L_s6-8_ROI")

# make networks factor
rsa$lang = rsa$roi %in% LANGrois$ROI
rsa$AT = rsa$roi %in% ATrois$ROI
rsa$PM = rsa$roi %in% PMrois$ROI

rsa$vischeck = grepl(".*V1_ROI",rsa$roi)
# rsa$vischeck = grepl(".*V\\d.*",rsa$roi)

# now assign group label in single column
rsa$roi_group = ifelse(rsa$PM == TRUE, "PM", ifelse(rsa$AT == TRUE, "AT", ifelse(rsa$lang == TRUE, "LANG", ifelse(rsa$vischeck == TRUE, "VIS", "other"))))

# delete the logical vectors
# rsa[,7:10] = NULL
# make group a factor
rsa$roi_group = as.factor(rsa$roi_group)

###### adding sub networks 
mpfc_subgroup = modulelabs %>% filter(sub_group == "mpfc")
pm_subgroup = modulelabs %>% filter(sub_group == "posterior_medial")
lp_subgroup = modulelabs %>% filter(sub_group == "lateral_parietal")
t_subgroup = modulelabs %>% filter(sub_group == "temporal")
d_subgroup = modulelabs %>% filter(sub_group == "dpfc")
mtl_subgroup = modulelabs %>% filter(sub_group == "mtl")

rsa$pm_subgroup = rsa$roi %in% pm_subgroup$ROI
rsa$mpfc_subgroup = rsa$roi %in% mpfc_subgroup$ROI
rsa$lp_subgroup = rsa$roi %in% lp_subgroup$ROI
rsa$t_subgroup = rsa$roi %in% t_subgroup$ROI
rsa$d_subgroup = rsa$roi %in% d_subgroup$ROI
rsa$mtl_subgroup = rsa$roi %in% mtl_subgroup$ROI

rsa$sub_group = ifelse(rsa$mpfc_subgroup == TRUE, "mpfc", ifelse(rsa$pm_subgroup == TRUE,"pm_sub",ifelse(rsa$lp_subgroup == TRUE, "lp",ifelse(rsa$t_subgroup == TRUE, "temporal",ifelse(rsa$d_subgroup == TRUE, "dorsal",ifelse(rsa$mtl_subgroup == TRUE, "mtl","tbd"))))))
rsa$sub_group = as.factor(rsa$sub_group)



rsa$othergroup = ifelse(rsa$sub_group == "lp" | rsa$sub_group == "pm_sub", "PM_super","other")

rsa[,8:12] = NULL
rsa[,9:14] = NULL



#############
# rsa = read_csv("2_25_19_univariate_glasser_df.csv")

#################
# rt  diffs
rt.diffs =  read.csv("rtdiffs_11_1_18.csv")
rt.diffs[,1] =NULL 

# rsa$sub_group = ifelse(rsa$sub_group == "tbd" & )
rsa$sub_group <- as.character(rsa$sub_group)
rsa$sub_group[rsa$roi_group == "AT" ] = "AT"
rsa$sub_group[rsa$roi_group == "VIS" ] = "VIS"
rsa$sub_group[rsa$roi_group == "LANG" ] = "LANG"
rsa$sub_group = as.factor(rsa$sub_group)

# infconn script just want sub_groups
rsa = rsa %>% group_by(sub,condition,sub_group,position,runnum,seqnum) %>% summarise(similarity = mean(bold)) %>%  ungroup()



# write_csv(rsa,"fconn_glass_dat.csv")

```

####
read data from condensed csvs
```{r}
library(tidyverse)
library(afex)
library(ggforce)
library('emmeans')
library(purrr)

rsa_hipp = read_csv("fconn_hipp_dat.csv")
rsa_glass = read_csv("fconn_glass_dat.csv")

rsa = bind_rows(rsa_hipp,rsa_glass)
rsa$sub_group = as.factor(rsa$sub_group)
rsa$sub = as.factor(rsa$sub)
rsa$runnum = as.factor(rsa$runnum)
rsa$condition = as.factor(rsa$condition)
rsa$seqnum = as.factor(rsa$seqnum)

# need to sort by seqnum ???

```



```{r}
# adding runnum grouping
fconn_func1 = function(subj,con1,region1,region2,run) {
  # grab grouped/meaned data for each condition 
  temp.df = rsa %>% filter(sub_group == region1) %>% filter(condition == con1, runnum == run,sub == subj) 
  temp.df = droplevels(temp.df)
  dat1 = temp.df$similarity
  
  temp.df = rsa %>% filter(sub_group == region2) %>% filter(condition == con1, runnum == run,sub == subj) 
  temp.df = droplevels(temp.df)
  dat2 = temp.df$similarity
  
  # run pearson
  if (length(dat1) == length(dat2)  && length(dat1) > 0){
    print(region1)
    print(region2)
    print(subj)
    result = cor.test(dat1, dat2)
    pval = result$p.value
    rval = result$estimate
  
    out = c(pval,unname(rval),subj,con1,region1,region2)
    return(out)
  } else {
    sprintf('problem with %s and %s !!!',region1,region2)
  }
}
```

```{r}
# this needs to be EXACTLY as verbose as it is. Ugh. 
df= data.frame(subj = as.vector(unique(rsa$sub)), stringsAsFactors = FALSE)
df =CartProduct(df,c("intact","scrambled"))
df$con1 = df$var2
df$var2 = NULL
df = CartProduct(df,as.vector(unique(rsa$sub_group)))
df$region1 = df$var2
df$var2 = NULL
df$con1 = as.character(df$con1)
df$region1 = as.character(df$region1)

# before moving forward need to check that this is reasonable way to to do FCONN and that same sequences are being correlated 
tstatdat = pmap(df,fconn_func1,region2 = "HIPP", run="run1")
tstatdat = data.frame(matrix(unlist(tstatdat), nrow=594, byrow=T))
tstatdat = plyr::rename(tstatdat, c("X1"="pval","X2"="rval","X3"="sub","X4"="condition","X5"="region1","X6"="region2"))

```



```{r}
CartProduct = function(CurrentMatrix, NewElement)
{
 
  if (length(dim(NewElement)) != 0 )
  {
    warning("New vector has more than one dimension.")
    return (NULL)
  }
 
  if (length(dim(CurrentMatrix)) == 0)
  {
    CurrentRows = length(CurrentMatrix)
    CurrentMatrix = as.matrix(CurrentMatrix, nrow = CurrentRows, ncol = 1)
  } else {
    CurrentRows = nrow(CurrentMatrix)
  }
 
  var1 = replicate(length(NewElement), CurrentMatrix, simplify=F)
  var1 = do.call("rbind", var1)
 
  var2 = rep(NewElement, CurrentRows)
  var2 = matrix(var2[order(var2)], nrow = length(var2), ncol = 1)
 
  CartProduct = cbind(var1, var2)
  CartProduct$var2 = as.character(CartProduct$var2)
  return (CartProduct)
}
```

```{r}
# adding runnum grouping
wbr.sliding.ttest.network = function(midval,region,winval,con1,con2,run) {
  # grab grouped/meaned data for each condition 
  temp.df = rsa %>% filter(sub_group == region) %>% filter(condition == con1, runnum == run) %>%   filter(position %in% (midval-winval):(midval+winval)) %>% group_by(sub) %>% summarise(similarity = mean(similarity)) %>%  ungroup()
  temp.df = droplevels(temp.df)
  dat1 = temp.df$similarity
  
  temp.df = rsa %>% filter(sub_group == region) %>% filter(condition == con2, runnum == run) %>%   filter(position %in% (midval-winval):(midval+winval)) %>% group_by(sub) %>% summarise(similarity = mean(similarity)) %>%  ungroup()
  temp.df = droplevels(temp.df)
  dat2 = temp.df$similarity
  
  # run ttest
  if (length(dat1) == length(dat2)  && length(dat1) > 0){
    print(region)
    result = t.test(dat1, dat2, paired = TRUE)
    pval = result$p.value
    tval = result$statistic
    out = c(pval,tval)
    return(out)
  } else {
    sprintf('problem with %s !!!',region )
  }
}
```

#nothing suuper eye catching in hippocampus by run analyses, except maybe overall slight tendency for more intact activity at the end of seqeunce in run1 

# huge effect for intact in PM at end of first run (hint of effect at the very beginning)
# second run looks quite different, early scrambled, then sustained intact in middle
# run 3 not a lot going on. scrambled early then NS sustained scrambled 

AT is actually pretty similar to PM

Lang also has late intact effect in run1
Early and late scrmabled in run2
nada in run3


PM effect in run 1
pm_sub up to 4.35 for late effect, flipping earlier, need to look not at difference
lp has early effect and late effect
mtl is peaked...
temporal nothing really

mpfc is -3.6 at tp 6 run2 -- 


tbd      mpfc     pm_sub   dorsal   lp       mtl      temporal
```{r}
# use this to get the true tstats for every timepoint. Chunk below will be used to ID cluster mass threshold
tstatdat = lapply(1:32,wbr.sliding.ttest.network,winval=0,region="PM",con1="intact",con2="scrambled", run="run3")
tstatdat = data.frame(matrix(unlist(tstatdat), nrow=32, byrow=T))
tstatdat$timepoint = 1:32
tstatdat = plyr::rename(tstatdat, c("X1"="pval","X2"="tval"))

#plot that shit
tstat.plot = ggplot(data = tstatdat,(aes(x =timepoint , y= tval,group =1)))  + geom_point(size = 3) +geom_line(size =2) + theme(text = element_text(size = 30, face = "bold"))  + ylab("t stat")  +
  geom_hline(aes(yintercept = 0)) + scale_y_continuous(limits= c(-4.5 , 4.5),breaks = c(-4,-3,-2,-1,0,1,2,3,4)) + ggtitle("PM univariate run3")
# geom_segment(x = 18,y =-.25,xend= 18,yend = .25, color = "red",size=.75) 

tstat.plot
# ggsave("july19/tstat_pm_uni_run3.pdf", plot = tstat.plot, dpi = 600,width = 8, height = 5,units = "in")
```

# line for each condition instead of difference/tstat line plot
```{r}

rsa.PM = rsa %>% filter(rsa$roi_group == "AT", condition != "random")
line.dat = rsa.PM  %>% group_by(condition,position,runnum) %>% summarise(similarity = mean(similarity))


PM.line = ggplot(data = line.dat, aes(x = position,group = condition, y = similarity)) + geom_line(aes(linetype=condition)) + facet_wrap(~runnum) + ylab("BOLD") + xlab("TR")
  # + theme(text = element_text(size = 30, face = "bold"),axis.title.x=element_blank(),axis.text.x=element_text(angle = -45,hjust = 0)) + scale_x_discrete(labels = c("Intact", "Same Verb","Same Position","Scrambled"))
  
PM.line
ggsave("july19/at_uni_meantimecourses_byrun.pdf", plot = PM.line, dpi = 600,width = 10, height = 5,units = "in")
```